{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb394bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "GPU: NVIDIA GeForce RTX 5070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198aa61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted and cleaned 6 documents\n",
      "Saved to: data\\extracted\\clean_text.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "import re\n",
    "import json\n",
    "\n",
    "RAW_PDF_DIR = Path(\"data/raw_pdfs\")\n",
    "OUTPUT_PATH = Path(\"data/extracted/clean_text.json\")\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Minimal but effective cleaning:\n",
    "    - remove page numbers\n",
    "    - remove extra whitespace\n",
    "    - normalize line breaks\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"\\n\\s*\\d+\\s*\\n\", \"\\n\", text)   # page numbers\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)           # extra spaces\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)        # large gaps\n",
    "    return text.strip()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for pdf_path in RAW_PDF_DIR.glob(\"*.pdf\"):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    full_text = []\n",
    "\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            full_text.append(page_text)\n",
    "\n",
    "    cleaned = clean_text(\"\\n\".join(full_text))\n",
    "\n",
    "    documents.append({\n",
    "        \"source\": pdf_path.name,\n",
    "        \"text\": cleaned\n",
    "    })\n",
    "\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(documents, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Extracted and cleaned {len(documents)} documents\")\n",
    "print(\"Saved to:\", OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a4b98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 6\n",
      "\n",
      "--- SAMPLE ---\n",
      "\n",
      "actualFA.pdf\n",
      "Page | 1 \n",
      " \n",
      "An introduction to first aid \n",
      " \n",
      "Imagine: Whilst feeding your child, they start to gag and appear unable to \n",
      "breathe. You have tried slapping them on the back, with no success. They seem \n",
      "close to losing consciousness, their lips are turning a definite shade of blue. \n",
      " \n",
      "People rarely give first aid a thought, until the day they need it. The above \n",
      "scenario is the sort of every day occurrence that can so easily lead to tragedy. \n",
      " \n",
      "However, with the correct first aid training anyone could, in the short term (until \n",
      "the arrival of the emergency services) save a life. \n",
      " \n",
      "These notes have been designed to aid you with your first aid training. It is, \n",
      "however, not a substitute for hands on training from a professional first aid \n",
      "trainer, but a reference for you to look back on when you need to. \n",
      " \n",
      "We hope the training you undertake with us will give you the knowledge and \n",
      "confidence to, if the worst happens, help keep someone alive. \n",
      " \n",
      " \n",
      "The Aims of first aid \n",
      " \n",
      "Preserve life \n",
      " Th\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open(\"data/extracted/clean_text.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    docs = json.load(f)\n",
    "\n",
    "print(\"Number of documents:\", len(docs))\n",
    "print(\"\\n--- SAMPLE ---\\n\")\n",
    "print(docs[0][\"source\"])\n",
    "print(docs[0][\"text\"][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b1043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1620 chunks\n",
      "Saved to: data\\extracted\\chunks.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "\n",
    "INPUT_PATH = Path(\"data/extracted/clean_text.json\")\n",
    "OUTPUT_PATH = Path(\"data/extracted/chunks.json\")\n",
    "\n",
    "MAX_WORDS = 320      # sweet spot\n",
    "OVERLAP_WORDS = 40   # light overlap\n",
    "\n",
    "with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "def chunk_text(text, max_words=MAX_WORDS, overlap=OVERLAP_WORDS):\n",
    "    paragraphs = [p.strip() for p in text.split(\"\\n\\n\") if p.strip()]\n",
    "    chunks = []\n",
    "    current = []\n",
    "    current_len = 0\n",
    "\n",
    "    for para in paragraphs:\n",
    "        words = para.split()\n",
    "        wlen = len(words)\n",
    "\n",
    "        # Case 1: paragraph itself is too large â†’ split it\n",
    "        if wlen > max_words:\n",
    "            for i in range(0, wlen, max_words - overlap):\n",
    "                sub = words[i:i + max_words]\n",
    "                chunks.append(\" \".join(sub))\n",
    "            current = []\n",
    "            current_len = 0\n",
    "            continue\n",
    "\n",
    "        # Case 2: normal accumulation\n",
    "        if current_len + wlen <= max_words:\n",
    "            current.append(para)\n",
    "            current_len += wlen\n",
    "        else:\n",
    "            # finalize current chunk\n",
    "            chunks.append(\" \".join(current))\n",
    "\n",
    "            # overlap\n",
    "            overlap_words = \" \".join(\" \".join(current).split()[-overlap:])\n",
    "            current = [overlap_words, para]\n",
    "            current_len = len(overlap_words.split()) + wlen\n",
    "\n",
    "    if current:\n",
    "        chunks.append(\" \".join(current))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "for doc in documents:\n",
    "    doc_chunks = chunk_text(doc[\"text\"])\n",
    "    for i, chunk in enumerate(doc_chunks):\n",
    "        all_chunks.append({\n",
    "            \"chunk_id\": f\"{doc['source']}_{i}\",\n",
    "            \"source\": doc[\"source\"],\n",
    "            \"text\": chunk\n",
    "        })\n",
    "\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Created {len(all_chunks)} chunks\")\n",
    "print(\"Saved to:\", OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95c7ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 1620\n",
      "\n",
      "--- SAMPLE CHUNK ---\n",
      "\n",
      "'actualFA.pdf_0'\n",
      "Page | 1 An introduction to first aid Imagine: Whilst feeding your child, they start to gag and appear unable to breathe. You have tried slapping them on the back, with no success. They seem close to losing consciousness, their lips are turning a definite shade of blue. People rarely give first aid a thought, until the day they need it. The above scenario is the sort of every day occurrence that can so easily lead to tragedy. However, with the correct first aid training anyone could, in the short term (until the arrival of the emergency services) save a life. These notes have been designed to aid you with your first aid training. It is, however, not a substitute for hands on training from a professional first aid trainer, but a reference for you to look back on when you need to. We hope th\n",
      "\n",
      "Word count: 320\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open(\"data/extracted/chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "print(\"Total chunks:\", len(chunks))\n",
    "print(\"\\n--- SAMPLE CHUNK ---\\n\")\n",
    "pprint(chunks[0][\"chunk_id\"])\n",
    "print(chunks[0][\"text\"][:800])\n",
    "print(\"\\nWord count:\", len(chunks[0][\"text\"].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea37564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded on: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "EMBED_MODEL_NAME = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBED_MODEL_NAME)\n",
    "embed_model = AutoModel.from_pretrained(EMBED_MODEL_NAME).to(device)\n",
    "embed_model.eval()\n",
    "\n",
    "print(\"Embedding model loaded on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c58a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts, batch_size=64):\n",
    "    \"\"\"\n",
    "    Embeds a list of texts using BGE-small.\n",
    "    Returns normalized float32 vectors (cosine-ready).\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "\n",
    "            inputs = tokenizer(\n",
    "                batch,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            outputs = embed_model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state[:, 0]   # CLS token\n",
    "            embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "\n",
    "    return torch.cat(all_embeddings, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f350d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (1620, 384)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/extracted/chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "\n",
    "embeddings = embed_texts(texts)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d842ae22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built\n",
      "Total vectors in index: 1620\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Ensure float32 (FAISS requirement)\n",
    "embeddings_f32 = embeddings.astype(\"float32\")\n",
    "\n",
    "dim = embeddings_f32.shape[1]\n",
    "\n",
    "# Inner Product index (cosine similarity because embeddings are normalized)\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "\n",
    "index.add(embeddings_f32)\n",
    "\n",
    "print(\"FAISS index built\")\n",
    "print(\"Total vectors in index:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e4a573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndianFAmanual.pdf_52\n",
      "coughing. Do not do anything else, but stay with the person until he breathes normally again. C.5.2.1.2 WHAT DO I DO IF THE PERSON CANNOT SPEAK, COUGH OR BREATHE? 1. Stand to the side and a little beh \n",
      "\n",
      "IndianFAmanual.pdf_51\n",
      "hanging to a healt hcare facility. C.5 CHOKING When a person is having severe difficulty in breathing because of an obstructed airway or lack of air, he is choking. Coughing is the natural way of clea \n",
      "\n",
      "IFRCmanual.pdf_276\n",
      "breathe Severe choking â€¢ Unable to cough, speak, cry or breathe â€¢ Clutches the throat with one or both hands â€¢ Panic â€¢ Bluish colour to the skin of the lips, ears, fingers and toes â€¢ Becomes unrespons \n",
      "\n",
      "StJohnFA.pdf_42\n",
      "casualty is breathing normally, place them in the recovery position (see pages 21-22) h If the casualty is not breathing normally, perform CPR (see pages 23-28) 2. Dial 999 or 112 for an ambulance 3.  \n",
      "\n",
      "canadianRCFA.pdf_68\n",
      "Choking4 partial choking, because it depends on creating pressure behind the blockage (which is impossible unless the blockage is complete). If the person is or becomes too weak to cough, his or her c \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def retrieve(query, k=5):\n",
    "    q_emb = embed_texts([query]).astype(\"float32\")\n",
    "    scores, indices = index.search(q_emb, k)\n",
    "    return [chunks[i] for i in indices[0]]\n",
    "\n",
    "# Test query\n",
    "results = retrieve(\"Someone is choking and cannot breathe\", k=5)\n",
    "\n",
    "for r in results:\n",
    "    print(r[\"chunk_id\"])\n",
    "    print(r[\"text\"][:200], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab5679cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, retrieved_chunks, max_context_chars=1200):\n",
    "    context_parts = []\n",
    "    total_len = 0\n",
    "\n",
    "    for c in retrieved_chunks:\n",
    "        text = c[\"text\"].strip()\n",
    "\n",
    "        if len(text) > 500:\n",
    "            text = text[:500]\n",
    "\n",
    "        part = text + \"\\n\"\n",
    "        if total_len + len(part) > max_context_chars:\n",
    "            break\n",
    "\n",
    "        context_parts.append(part)\n",
    "        total_len += len(part)\n",
    "\n",
    "    context = \"\\n\".join(context_parts)\n",
    "\n",
    "    prompt = f\"\"\"### SYSTEM\n",
    "You are a first-aid reference assistant.\n",
    "Follow the rules strictly.\n",
    "\n",
    "Rules:\n",
    "- Use ONLY the context.\n",
    "- Write numbered steps.\n",
    "- Use simple language.\n",
    "- Do NOT repeat instructions.\n",
    "- Do NOT include sources.\n",
    "- Stop when finished.\n",
    "- If the person becomes unconscious, advise calling emergency services.\n",
    "\n",
    "### CONTEXT\n",
    "{context}\n",
    "\n",
    "### QUESTION\n",
    "{query}\n",
    "\n",
    "### ANSWER\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccdd8828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length (characters): 1898\n",
      "\n",
      "--- PROMPT PREVIEW ---\n",
      "\n",
      "You are a first-aid reference assistant.\n",
      "\n",
      "Use ONLY the information in the context below.\n",
      "Write clear, numbered first-aid steps.\n",
      "Use simple language.\n",
      "Do NOT diagnose medical conditions.\n",
      "\n",
      "Context:\n",
      "[IndianFAmanual.pdf]\n",
      "coughing. Do not do anything else, but stay with the person until he breathes normally again. C.5.2.1.2 WHAT DO I DO IF THE PERSON CANNOT SPEAK, COUGH OR BREATHE? 1. Stand to the side and a little behind the choking person or child ( aged older than one year). 2. Support the personâ€™s chest with one hand and bend him forward. 3. Give five firm blows between the personâ€™s shoulder blades. To do so, use the heel of your free hand. Verify if the object has come out and the person can breathe again. C.5.2.1.3 WHAT DO I DO IF THE OBJECT DID NOT COME OUT AND THE PERSON IS STILL CHOKING? 1. Stand behind the choking person and put both hands around him, so your hands meet in front of the person. 2. Make a fist and place it between the navel and lower tip of the breastbone of the person. Hold onto th\n",
      "\n",
      "[IndianFAmanual.pdf]\n",
      "hanging to a healt hcare facility. C.5 CHOKING When a person is having severe difficulty in breathing because of an obstructed airway or lack of air, he is choking. Coughing is the natural way of clearing the airway when the person experiences mild choking. It is also a sign that he still gets air through the windpipe. Severe choking happens when the foreign object or a local swelling blocks the airway. This is a life-threatening emergency. Infants and chil\n"
     ]
    }
   ],
   "source": [
    "test_chunks = retrieve(\"Someone is choking and cannot breathe\", k=3)\n",
    "prompt = build_prompt(\"Someone is choking and cannot breathe\", test_chunks)\n",
    "\n",
    "print(\"Prompt length (characters):\", len(prompt))\n",
    "print(\"\\n--- PROMPT PREVIEW ---\\n\")\n",
    "print(prompt[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5fa61fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=r\"C:\\Projects\\firstAidChatbot\\models\\Phi-3-mini-4k-instruct-q4.gguf\",\n",
    "\n",
    "    # Context\n",
    "    n_ctx=2048,\n",
    "\n",
    "    # CPU threading (CRITICAL)\n",
    "    n_threads=24,          # physical cores\n",
    "    n_threads_batch=24,    # prompt evaluation\n",
    "\n",
    "    # Batch size (CRITICAL)\n",
    "    n_batch=1024,          # fast prompt ingestion\n",
    "\n",
    "    # Memory optimizations\n",
    "    use_mmap=True,\n",
    "    use_mlock=True,\n",
    "\n",
    "    # Generation behavior (first-aid safe)\n",
    "    temperature=0.0,\n",
    "    top_p=1.0,\n",
    "    repeat_penalty=1.08,\n",
    "\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b48c6269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(prompt: str) -> str:\n",
    "    output = llm(\n",
    "        prompt,\n",
    "        max_tokens=120,\n",
    "        stop=[\n",
    "            \"###\",\n",
    "            \"<|assistant|>\",\n",
    "            \"<|user|>\"\n",
    "        ]\n",
    "    )\n",
    "    return output[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a37366e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(query, top_k=3):\n",
    "    retrieved = retrieve(query, k=top_k)\n",
    "    prompt = build_prompt(query, retrieved)\n",
    "    answer = generate_answer(prompt)\n",
    "    return answer, [(c[\"chunk_id\"], c[\"source\"]) for c in retrieved]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7a5516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response time: 6.2 seconds\n",
      "\n",
      "ANSWER:\n",
      " 1. Stand to the side and slightly behind the choking person.\n",
      "\n",
      "2. Support the person's chest with one hand and bend them forward.\n",
      "\n",
      "3. Give five firm blows between the person's shoulder blades.\n",
      "\n",
      "4. Verify if the obstruction has been cleared and the person can breathe.\n",
      "\n",
      "5. If the person does not become unresponsive, continue to monitor them.\n",
      "\n",
      "If the person becomes unresponsive, advise calling emergency services.\n",
      "\n",
      "SOURCES:\n",
      "- IndianFAmanual.pdf_52\n",
      "- IFRCmanual.pdf_276\n",
      "- IndianFAmanual.pdf_53\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query = \"Someone is choking and cannot breathe. What should I do?\"\n",
    "\n",
    "start = time.time()\n",
    "answer, sources = rag_answer(query)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(\"Response time:\", round(elapsed, 2), \"seconds\\n\")\n",
    "print(\"ANSWER:\\n\", answer)\n",
    "print(\"\\nSOURCES:\")\n",
    "for s in sources:\n",
    "    print(\"-\", s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "203a141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# -------------------------------\n",
    "# STREAMING GENERATION\n",
    "# -------------------------------\n",
    "\n",
    "def generate_answer_stream(prompt: str):\n",
    "    stream = llm(\n",
    "        prompt,\n",
    "        max_tokens=150,\n",
    "        stop=[\"###\", \"<|assistant|>\", \"<|user|>\"],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    partial = \"\"\n",
    "    for chunk in stream:\n",
    "        token = chunk[\"choices\"][0][\"text\"]\n",
    "        partial += token\n",
    "        yield partial\n",
    "\n",
    "\n",
    "def rag_answer_stream(query):\n",
    "    retrieved = retrieve(query, k=3)\n",
    "    prompt = build_prompt(query, retrieved)\n",
    "    return generate_answer_stream(prompt)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# GRADIO CHAT STREAM FUNCTION\n",
    "# -------------------------------\n",
    "\n",
    "def chat_stream(user_message, history):\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    # append user message\n",
    "    history.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    })\n",
    "\n",
    "    # append empty assistant message\n",
    "    history.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\n",
    "    })\n",
    "\n",
    "    stream = rag_answer_stream(user_message)\n",
    "\n",
    "    for partial in stream:\n",
    "        history[-1][\"content\"] = partial\n",
    "        yield history\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# GRADIO UI\n",
    "# -------------------------------\n",
    "\n",
    "with gr.Blocks(title=\"First Aid Assistant\") as demo:\n",
    "    gr.Markdown(\"## ðŸ©º First Aid Assistant\")\n",
    "    gr.Markdown(\n",
    "        \"Fast, offline, retrieval-augmented first-aid guidance. \"\n",
    "        \"This tool does not replace professional medical care.\"\n",
    "    )\n",
    "\n",
    "    chatbot = gr.Chatbot(height=420)\n",
    "\n",
    "    msg = gr.Textbox(\n",
    "        placeholder=\"Ask a first aid questionâ€¦\",\n",
    "        show_label=False\n",
    "    )\n",
    "\n",
    "    msg.submit(\n",
    "        chat_stream,\n",
    "        inputs=[msg, chatbot],\n",
    "        outputs=chatbot,\n",
    "        queue=True\n",
    "    )\n",
    "\n",
    "    msg.submit(lambda: \"\", None, msg)\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
